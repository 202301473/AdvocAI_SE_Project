from rest_framework.decorators import api_view, parser_classes
from rest_framework.response import Response
from django.conf import settings
import google.generativeai as genai
import json
from django.http import FileResponse
import markdown
from xhtml2pdf import pisa
from io import BytesIO
# Note: mongo_client functions not used in this refactored version
# from .mongo_client import get_all_conversations, get_conversation_by_id, save_conversation, update_conversation, delete_conversation, get_document_version_content
from rest_framework import status
from rest_framework.parsers import MultiPartParser, FormParser, JSONParser
from django.utils.crypto import get_random_string
import os
import cloudinary.uploader
from typing import TypedDict, Annotated, Sequence
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
import operator
# Note: mongo_client functions not used in this refactored version
# from .mongo_client import get_all_conversations, get_conversation_by_id, save_conversation, update_conversation, delete_conversation, get_document_version_content

# ============================================================================
# SYSTEM PROMPT - The AI's "Personality"
# ============================================================================
SYSTEM_PROMPT = """## 1. ðŸ“œ Role and Identity
You are an expert AI Legal Drafting Assistant.
* **Persona:** Precise, helpful, and cautious.
* **Primary Jurisdiction:** Your primary focus and expertise is the **jurisdiction of India**.
* **Fallback Jurisdiction:** If an India-specific document is not feasible or not requested, you will provide a **generic, jurisdiction-agnostic** template as a starting point.

## 2. ðŸŽ¯ Core Mandate
Your primary function is to assist users by:
* **Generating First Drafts:** Create preliminary drafts of legal documents, prioritizing Indian formats.
* **Asking Clarifying Questions:** Proactively gather all necessary variables (names, addresses, amounts, dates, etc.).
* **Utilizing Search:** You must use your search tools to find relevant templates, common clauses, and jurisdiction-specific information (especially for India) to inform your draft.
* **Structuring Documents:** Format all output according to standard legal conventions.
* **Explaining Clauses:** Describe the general purpose of common clauses in a purely educational and informational context.

## 3. ðŸ›‘ CRITICAL GUARDRAIL: The "No Legal Advice" Directive
This is your most important rule. You are a drafting tool, **NOT a lawyer**. You **CANNOT** provide legal advice, legal opinions, or any form of legal counsel.

**The Rule:**
You must **never** interpret a user's specific situation, predict a legal outcome, or give an opinion on the fairness or legality of a situation. (e.g., Refuse "Is this contract fair?").

**Mandatory Actions:**
1.  **Refuse Legal Advice:** If asked for an opinion, you must refuse.
2.  **State Your Limitation:** Politely state your role: "I cannot provide legal advice. My purpose is to help you draft a document. For a review of your specific situation or for legal counsel, you must consult a qualified legal professional."
3.  **Include a Dynamic Disclaimer:** You must select and append the correct disclaimer from the two options below.

## 4. âš–ï¸ Dynamic Disclaimer System (MANDATORY)
You must choose **one** of the following disclaimers to append to **every** draft you generate.

> **Disclaimer A (Use for India-Specific Drafts):**
> ---
> **IMPORTANT DISCLAIMER (INDIA):** This document was generated by an AI assistant. It is for informational and drafting purposes ONLY and is NOT a substitute for legal advice. It is intended as a starting point based on common formats in India. Laws and regulations vary, and this draft may not be suitable for your specific needs. **You MUST consult a qualified legal professional in India** to review this document, ensure its compliance, and advise you on your specific legal situation before using it.
> ---

> **Disclaimer B (Use for Generic/Agnostic Drafts):**
> ---
> **IMPORTANT DISCLAIMER (GENERIC):** This document was generated by an AI assistant and is a generic template. It is NOT specific to any country, state, or jurisdiction. It is for informational and drafting purposes ONLY and is NOT a substitute for legal advice. This draft WILL NOT be compliant without a thorough review and customization by a legal expert. It is CRITICAL that you consult a qualified legal professional in your specific jurisdiction to review and adapt this document to your needs before using it.
> ---

## 5. ðŸ‡®ðŸ‡³ Operational Guidelines
* **Jurisdictional Priority:** Priority 1 is India (use search for local laws). Priority 2 is Generic.
* **Search Integration:** Use search as a standard step to verify terminology and find document templates *before* you start drafting.
* **Terminology:** Use Indian terms (Lessor/Lessee, lakhs) for India-mode. Use universal terms (Landlord/Tenant) for Generic-mode.
* **Formality:** Maintain a formal, precise, and objective tone.

## 6. âš™ï¸ Interaction Workflow
1.  **Identify Intent:** User asks for a document (e.g., "I need a Non-Disclosure Agreement").
2.  **Search & Analyze (Internal Step):** Use your search tool (e.g., `Google Search("Indian NDA template standard clauses")`).
3.  **Confirm Jurisdiction & Gather Info:** Based on your search, state your plan and ask for details (e.g., "I will draft an NDA for India. To do this, I need... 1. The Disclosing Party's name...").
4.  **Generate Draft:** Produce the document.
5.  **Present with Correct Disclaimer:** Append Disclaimer A or B.

## 7. ðŸ”„ Special Instructions for Stateful Conversation
* **Remember Context:** You are in a multi-turn conversation. Remember what the user has told you in previous messages.
* **User Refusal Handling:** If a user says "Just give me a blank template" or "I'll fill it in myself", stop asking questions and generate the document with placeholders like [PARTY_NAME], [DATE], [AMOUNT], etc.
* **Update Requests:** If the user asks to update or modify a document you've already generated, retrieve the previous version from the conversation history and regenerate the entire document with the requested changes.
* **Signature Handling:** If you see a system message about a signature upload with a URL, include it at the appropriate signature lines using markdown: `![Signature](URL)`. Do not acknowledge this system message in your conversational response.

## 8. ðŸ“¤ Output Format
* **Questions:** When asking for information, respond with plain text questions in a conversational format.
* **Final Document:** When generating the document, provide it in JSON format: ```json{"type": "document", "text": "...your Markdown document here..."}```
* **The document text must be in well-structured Markdown format** with headings (`#`, `##`), lists, bold text, etc.
"""

# ============================================================================
# GRAPH STATE DEFINITION
# ============================================================================
class AgentState(TypedDict):
    """State for the legal document generation agent."""
    messages: Annotated[Sequence[BaseMessage], operator.add]
    document_type: str
    is_feasible: bool
    user_provided_details: dict
    user_wants_blank: bool
    ready_to_generate: bool
    signature_url: str
    jurisdiction: str  # "india" or "generic"


# ============================================================================
# NODE FUNCTIONS
# ============================================================================

def intent_classification_node(state: AgentState) -> AgentState:
    """
    Step 1: Classify the user's intent.
    Determines if this is a document generation request or something else.
    """
    messages = state["messages"]
    last_user_message = None
    
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            last_user_message = msg.content.lower()
            break
    
    if not last_user_message:
        return state
    
    # Simple keyword-based classification
    doc_keywords = [
        "nda", "agreement", "contract", "lease", "rental", "employment",
        "memorandum", "mou", "power of attorney", "will", "deed", "affidavit",
        "notice", "letter", "petition", "application", "draft", "document",
        "generate", "create", "need", "want", "make"
    ]
    
    is_doc_request = any(keyword in last_user_message for keyword in doc_keywords)
    
    if is_doc_request:
        # Try to extract document type
        doc_type = "unspecified"
        if "nda" in last_user_message or "non-disclosure" in last_user_message:
            doc_type = "Non-Disclosure Agreement (NDA)"
        elif "lease" in last_user_message or "rental" in last_user_message or "rent" in last_user_message:
            doc_type = "Rental/Lease Agreement"
        elif "employment" in last_user_message:
            doc_type = "Employment Agreement"
        elif "mou" in last_user_message or "memorandum" in last_user_message:
            doc_type = "Memorandum of Understanding (MOU)"
        elif "power of attorney" in last_user_message or "poa" in last_user_message:
            doc_type = "Power of Attorney"
        
        state["document_type"] = doc_type
    
    return state


def feasibility_check_node(state: AgentState) -> AgentState:
    """
    Step 2: Check if the requested document is feasible.
    Too complex documents should be rejected.
    """
    if not state.get("document_type") or state["document_type"] == "unspecified":
        state["is_feasible"] = True  # Let the agent handle clarification
        return state
    
    # List of overly complex document types
    complex_docs = [
        "merger", "acquisition", "ipo", "securities", "international",
        "cross-border", "intellectual property portfolio", "patent licensing",
        "joint venture", "corporate restructuring", "bankruptcy"
    ]
    
    doc_type_lower = state["document_type"].lower()
    
    if any(complex in doc_type_lower for complex in complex_docs):
        state["is_feasible"] = False
    else:
        state["is_feasible"] = True
    
    return state


def information_gathering_node(state: AgentState) -> AgentState:
    """
    Step 3: Stateful information gathering.
    The agent asks questions and stores answers in state.
    """
    messages = state["messages"]
    
    # Check if user wants a blank template
    last_user_message = None
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            last_user_message = msg.content.lower()
            break
    
    if last_user_message:
        blank_indicators = [
            "blank template", "blank", "fill it in myself", "fill in myself",
            "i'll fill", "empty template", "just give me", "placeholder"
        ]
        if any(indicator in last_user_message for indicator in blank_indicators):
            state["user_wants_blank"] = True
            state["ready_to_generate"] = True
            return state
    
    # Check for signature upload system message
    for msg in messages:
        if isinstance(msg, HumanMessage) and "(System: The user has uploaded a signature" in msg.content:
            # Extract URL from system message
            try:
                url_start = msg.content.find("![Signature](") + len("![Signature](")
                url_end = msg.content.find(")", url_start)
                signature_url = msg.content[url_start:url_end]
                state["signature_url"] = signature_url
            except:
                pass
    
    # Simple heuristic: if we have more than 3 exchanges, assume we have enough info
    user_message_count = sum(1 for msg in messages if isinstance(msg, HumanMessage))
    
    if user_message_count >= 3:
        state["ready_to_generate"] = True
    
    return state


def should_continue_gathering(state: AgentState) -> str:
    """
    Routing function: decides whether to continue gathering info or generate document.
    """
    if not state.get("is_feasible", True):
        return "reject"
    
    if state.get("ready_to_generate", False):
        return "generate"
    
    return "gather"


# ============================================================================
# MAIN AGENT NODE (LLM Integration)
# ============================================================================

def agent_node(state: AgentState) -> AgentState:
    """
    The main LLM-powered agent node.
    This handles all the actual conversation and generation.
    """
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=settings.GEMINI_API_KEY,
        temperature=0.7
    )
    
    messages = state["messages"]
    
    # Build the context for the LLM
    context_additions = []
    
    if not state.get("is_feasible", True):
        context_additions.append(
            "SYSTEM INSTRUCTION: The user has requested a document that is too complex. "
            "You must politely inform them: 'I am not capable of generating a document of that complexity. "
            "Such documents require specialized legal expertise. Please consult a qualified legal professional.'"
        )
    
    if state.get("user_wants_blank", False):
        context_additions.append(
            "SYSTEM INSTRUCTION: The user has requested a blank template with placeholders. "
            "Generate the document now with placeholders like [PARTY_NAME], [DATE], [AMOUNT], etc. "
            "Do not ask any more questions."
        )
    
    if state.get("ready_to_generate", False) and not state.get("user_wants_blank", False):
        context_additions.append(
            "SYSTEM INSTRUCTION: You have gathered sufficient information. "
            "Generate the complete document now using all the details provided in the conversation. "
            "Include the appropriate disclaimer (India or Generic) at the end."
        )
    
    if state.get("document_type") and state.get("document_type") != "unspecified":
        context_additions.append(
            f"SYSTEM INSTRUCTION: The user needs a {state['document_type']}. "
            "Ask for the necessary details to draft this document."
        )
    
    # Prepare messages with system prompt and context
    full_messages = [SystemMessage(content=SYSTEM_PROMPT)]
    
    if context_additions:
        full_messages.append(SystemMessage(content="\n\n".join(context_additions)))
    
    full_messages.extend(messages)
    
    # Call the LLM
    response = llm.invoke(full_messages)
    
    # Add the AI's response to state
    ai_message = AIMessage(content=response.content)
    
    return {
        "messages": [ai_message],
        "document_type": state.get("document_type", ""),
        "is_feasible": state.get("is_feasible", True),
        "user_provided_details": state.get("user_provided_details", {}),
        "user_wants_blank": state.get("user_wants_blank", False),
        "ready_to_generate": state.get("ready_to_generate", False),
        "signature_url": state.get("signature_url", ""),
        "jurisdiction": state.get("jurisdiction", "india")
    }


# ============================================================================
# BUILD THE GRAPH
# ============================================================================

def create_document_generation_graph():
    """
    Creates and returns the LangGraph for document generation.
    """
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("intent_classification", intent_classification_node)
    workflow.add_node("feasibility_check", feasibility_check_node)
    workflow.add_node("agent", agent_node)
    workflow.add_node("information_gathering", information_gathering_node)
    
    # Define edges
    workflow.set_entry_point("intent_classification")
    
    workflow.add_edge("intent_classification", "feasibility_check")
    workflow.add_edge("feasibility_check", "agent")
    workflow.add_edge("agent", "information_gathering")
    
    # Conditional routing from information_gathering
    workflow.add_conditional_edges(
        "information_gathering",
        should_continue_gathering,
        {
            "reject": END,
            "generate": END,
            "gather": "agent"
        }
    )
    
    # Compile with memory
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    
    return app


# Global graph instance (initialized once)
document_graph = None


def get_document_graph():
    """
    Lazy initialization of the graph.
    """
    global document_graph
    if document_graph is None:
        document_graph = create_document_generation_graph()
    return document_graph


# ============================================================================
# API ENDPOINT
# ============================================================================

@api_view(['POST'])
@parser_classes([MultiPartParser, FormParser, JSONParser])
def chat(request):
    """
    API endpoint for the conversational legal document generator.
    Now powered by a stateful LangGraph agent.
    """
    if not settings.GEMINI_API_KEY or settings.GEMINI_API_KEY == '':
        return Response(
            {'error': 'GEMINI_API_KEY is not configured in your .env file or is empty.'},
            status=500
        )

    messages = request.data.get('messages', [])
    if not messages:
        return Response({'error': 'Messages are required'}, status=400)

    try:
        # Handle signature upload
        signature_file = request.FILES.get('signature')
        if signature_file:
            try:
                upload_result = cloudinary.uploader.upload(signature_file)
                signature_url = upload_result['secure_url']
                # Append a system message to the user's message
                messages[-1]['text'] += (
                    f"\n\n(System: The user has uploaded a signature. "
                    f"Please place it in the appropriate section of the document "
                    f"using the following markdown: ![Signature]({signature_url}))"
                )
            except Exception as e:
                return Response({'error': f'Error uploading signature: {e}'}, status=500)

        # Convert messages to LangChain format
        lc_messages = []
        for msg in messages:
            if msg['sender'] == 'user':
                lc_messages.append(HumanMessage(content=msg['text']))
            else:
                lc_messages.append(AIMessage(content=msg['text']))

        # Get or create session ID (you can use user ID or generate one)
        session_id = request.data.get('session_id', 'default_session')
        
        # Initialize state for first message
        if len(lc_messages) == 1:
            initial_state = {
                "messages": lc_messages,
                "document_type": "",
                "is_feasible": True,
                "user_provided_details": {},
                "user_wants_blank": False,
                "ready_to_generate": False,
                "signature_url": "",
                "jurisdiction": "india"
            }
        else:
            # For subsequent messages, only add the new message
            initial_state = {
                "messages": [lc_messages[-1]],
                "document_type": "",
                "is_feasible": True,
                "user_provided_details": {},
                "user_wants_blank": False,
                "ready_to_generate": False,
                "signature_url": "",
                "jurisdiction": "india"
            }

        # Get the graph and run it
        graph = get_document_graph()
        config = {"configurable": {"thread_id": session_id}}
        
        # Run the graph
        result = graph.invoke(initial_state, config)
        
        # Extract the last AI message
        last_ai_message = None
        for msg in reversed(result["messages"]):
            if isinstance(msg, AIMessage):
                last_ai_message = msg.content
                break
        
        if not last_ai_message:
            return Response({'error': 'No response from agent'}, status=500)

        # Check if it's a document or a question
        if '```json' in last_ai_message:
            # It's the final document
            json_str = last_ai_message.split('```json')[1].split('```')[0].strip()
            document_data = json.loads(json_str)
            return Response(document_data)
        else:
            # It's a question or intermediate response
            return Response({'type': 'question', 'text': last_ai_message})

    except Exception as e:
        print(f"Error in chat view: {e}")
        print(f"Type of error: {type(e)}")
        import traceback
        traceback.print_exc()
        return Response({'error': str(e)}, status=500)


@api_view(['POST'])
def download_pdf(request):
    """
    API endpoint to download a legal document as PDF.
    """
    document_content = request.data.get('document_content')
    if not document_content:
        return Response({'error': 'Document content is required'}, status=400)

    try:
        pdf_file = _generate_pdf_from_markdown(document_content)
        response = FileResponse(pdf_file, content_type='application/pdf')
        response['Content-Disposition'] = 'attachment; filename="legal_document.pdf"'
        return response
    except Exception as e:
        return Response({'error': f'Error generating PDF: {e}'}, status=500)


@api_view(['POST'])
def preview_document(request):
    """
    API endpoint to preview a legal document as HTML.
    """
    document_content = request.data.get('document_content')
    if not document_content:
        return Response({'error': 'Document content is required'}, status=400)

    try:
        # Convert markdown to HTML
        html_content = markdown.markdown(
            document_content,
            extensions=['extra', 'nl2br', 'sane_lists']
        )
        
        # Add styling for better preview
        styled_html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <style>
                body {{
                    font-family: "Times New Roman", Times, serif;
                    font-size: 11pt;
                    line-height: 1.5;
                    max-width: 800px;
                    margin: 20px auto;
                    padding: 20px;
                    background-color: #f5f5f5;
                }}
                .document {{
                    background-color: white;
                    padding: 40px;
                    box-shadow: 0 0 10px rgba(0,0,0,0.1);
                }}
                h1 {{
                    text-align: center;
                    font-size: 18pt;
                    margin-bottom: 30px;
                    text-transform: uppercase;
                }}
                h2 {{
                    font-size: 14pt;
                    margin-top: 20px;
                    border-bottom: 1px solid #000;
                    padding-bottom: 5px;
                }}
                h3 {{
                    font-size: 12pt;
                    margin-top: 15px;
                    text-decoration: underline;
                }}
                p {{
                    text-align: justify;
                    margin-bottom: 10px;
                }}
                ul, ol {{
                    margin-bottom: 10px;
                }}
                table {{
                    width: 100%;
                    border-collapse: collapse;
                    margin: 15px 0;
                }}
                th, td {{
                    border: 1px solid #333;
                    padding: 8px;
                    text-align: left;
                }}
                th {{
                    background-color: #e0e0e0;
                    font-weight: bold;
                }}
                img {{
                    max-width: 200px;
                    height: auto;
                }}
            </style>
        </head>
        <body>
            <div class="document">
                {html_content}
            </div>
        </body>
        </html>
        """
        
        return Response({'html': styled_html})
    except Exception as e:
        return Response({'error': f'Error generating preview: {e}'}, status=500)

def _generate_pdf_from_markdown(markdown_content):
    """
    Helper function to convert markdown string to a PDF file response.
    This function is used by the download_pdf view.
    """
    html_content = markdown.markdown(markdown_content)

    pdf_style_css = """
        @page {
            size: a4 portrait;
            margin: 1.2cm;
        }
        body {
            font-family: "Times New Roman", Times, serif;
            font-size: 11pt;
            line-height: 1.3;
            color: #000000;
        }
        h1, h2, h3, h4, h5, h6 {
            font-family: "Times New Roman", Times, serif;
            font-weight: bold;
            color: #000000;
            margin-top: 1.2em;
            margin-bottom: 0.6em;
            line-height: 1.15;
        }
        h1 {
            font-size: 16pt;
            text-align: center;
            text-transform: uppercase;
            margin-bottom: 1.5em;
        }
        h2 {
            font-size: 14pt;
            text-transform: uppercase;
            border-bottom: 1px solid #000000;
            padding-bottom: 0.2em;
        }
        h3 {
            font-size: 12pt;
            font-weight: bold;
            text-decoration: underline;
        }
        p {
            margin-bottom: 0.8em;
            text-align: justify;
            text-indent: 1.25cm; /* Indent first line of paragraphs */
        }
        /* Don't indent first paragraph after a heading */
        h1 + p, h2 + p, h3 + p, h4 + p, h5 + p, h6 + p {
            text-indent: 0;
        }
        ul, ol {
            margin-bottom: 0.8em;
            padding-left: 1.5cm;
        }
        li {
            margin-bottom: 0.3em;
            text-align: justify;
        }
        strong, b {
            font-weight: bold;
        }
        em, i {
            font-style: italic;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1em;
            border: 1px solid #333333;
        }
        th, td {
            border: 1px solid #333333;
            padding: 6px;
            text-align: left;
            vertical-align: top;
        }
        th {
            background-color: #e0e0e0;
            font-weight: bold;
        }
        hr {
            width: 250px;
            margin-left: 0;
            border: 0.5px solid #000;
        }
        /* Signature sizing and spacing */
        img[alt~="signature"][alt~="landlord"] {
            display: block;
            width: 180px;
            height: 80px;
            object-fit: contain;
            margin-top: 8mm;   /* place below landlord text */
            margin-bottom: 0;
        }
        img[alt~="signature"][alt~="tenant"] {
            display: block;
            width: 180px;
            height: 80px;
            object-fit: contain;
            margin-top: 0;
            margin-bottom: 8mm; /* place above tenant text */
        }
        /* Remove header and footer for a more traditional look */
    """

    full_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Legal Document</title>
        <meta charset=\"utf-8\">
        <style>{pdf_style_css}</style>
    </head>
    <body>{html_content}</body>
    </html>
    """

    result_file = BytesIO()
    pisa_status = pisa.CreatePDF(full_html, dest=result_file)

    if pisa_status.err:
        raise Exception(f'PDF generation error: {pisa_status.err}')

    result_file.seek(0)
    return result_file
